---
title: "\\LARGE Using contrastive inferences to learn about new words and categories"
author: "\\large \\emph{Claire Bergey and Daniel Yurovsky}"
header-includes:
  - \usepackage[section]{placeins}
  - \usepackage{float}
  - \floatplacement{figure}{h!} # make every figure with caption = t
  - \raggedbottom
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
documentclass: article
bibliography: contrast.bib
fontsize: 11pt
geometry: margin=1in
csl: apa6.csl
---

```{r load-libraries, message=FALSE, warning=FALSE, include = F}
library(readxl)
library(janitor)
library(here)
library(knitr)
library(papaja)
library(kableExtra)
library(tidyverse)
library(tidyboot)
library(feather)
library(lme4)
library(lmerTest)
library(broom)
library(broom.mixed)
library(effectsize)
library(glue)
library(directlabels)
library(ggthemes)
library(rwebppl)

opts_chunk$set(message = FALSE, warning = FALSE, error = FALSE, cache = TRUE, 
               tidy = FALSE, echo = FALSE, fig.width = 3, fig.height = 3)

theme_set(theme_classic(base_size = 12))
options(digits=2)
```

```{r make-text-vars}
make_text_vars <- function(df, term_name, term_filter = NULL) {
  if(!is.null(term_filter)) {
    filtered_df <- df %>%
      filter(term == term_filter) 
  } else{
    filtered_df <- df
  }
    
  walk(c("estimate", "statistic", "p.value"), 
      ~assign(glue("{term_name}_{.x}"), 
              filtered_df %>% pull(!!.x), 
         envir = globalenv()))
}
```
\renewcommand\thesection{S\arabic{section}}
\renewcommand{\thetable}{S\arabic{table}}  
\renewcommand{\thefigure}{S\arabic{figure}}
\section{Experiment 1}

```{r load-data}
e1_raw_data <- read_csv(here("data/exp1_turk_data.csv"),
                        show_col_types = FALSE) 

e1_total_subjs <- e1_raw_data %>%
  distinct(subid) %>%
  count() %>%
  pull()

e1_total_color_subjs <- e1_raw_data %>%
  filter(condition == "color") %>%
  distinct(subid) %>%
  count() %>%
  pull()

e1_total_size_subjs <- e1_raw_data %>%
  filter(condition == "size") %>%
  distinct(subid) %>%
  count() %>%
  pull()


e1_keep_subjs <- e1_raw_data %>%
  filter(searchtype == "colorcheck", chosetarget == TRUE, 
         attncheckscore >= 6) %>%
  count(subid) %>%
  filter(n == 4) %>%
  pull(subid)

e1_data_no_gather <- e1_raw_data %>%
  filter(subid %in% e1_keep_subjs,
         trialtype != 0) %>%
  mutate(subid = as.factor(subid))

e1_data <- e1_raw_data %>%
  filter(subid %in% e1_keep_subjs,
         trialtype != 0) %>%
  pivot_longer(cols = c(chosetarget, choselure, choseunique), 
               names_to = "item", values_to = "chose") %>%
  mutate(item = gsub("chose", "", item),
         subid = as.factor(subid))

e1_color_subjs <- e1_data %>%
  filter(condition == "color") %>%
  distinct(subid) %>%
  nrow()

e1_size_subjs <- e1_data %>%
  filter(condition == "size") %>%
  distinct(subid) %>%
  nrow()

e1_mean_data <- e1_data %>%
  filter(item != "unique") %>%
  group_by(condition, searchtype, adj, item, subid) %>%
  summarise(chose = mean(chose)) %>%
  tidyboot_mean(chose) %>%
  ungroup() %>%
  mutate(adjective_used = factor(adj, labels = c("noun", "adjective noun"))) 


# full model to report in supplemental, pre-reg'd
# full adj * searchtype random effect model didn't converge. 
# searchtype + 1 also didn't converge. 1+ adj converges.
full_model <- e1_data_no_gather %>%
  glmer(chosetarget ~ adj * condition * searchtype + (1 + adj | subid),
        family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")  %>%
  mutate(p.value = printp(p.value))

walk2(c("e1full_adj", "e1full_size","e1full_uniquetarget","e1full_adj_size", 
        "e1full_adj_uniquetarget","e1full_size_uniquetarget", 
        "e1full_adj_size_uniquetarget"),
      c("adjTRUE", "conditionsize", "searchtypeuniquetarget", 
        "adjTRUE:conditionsize", "adjTRUE:searchtypeuniquetarget", 
        "conditionsize:searchtypeuniquetarget", 
        "adjTRUE:conditionsize:searchtypeuniquetarget"),  
      ~make_text_vars(full_model, .x, .y))
```

```{r e1-table}

full_model %>%
  select(-effect, -group, -std.error) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "Intercept" ~ "intercept",
    term == "adjTRUE" ~ "adjective (vs. no adjective)",
    term == "conditionsize" ~ "size (vs. color)",
    term == "searchtypeuniquetarget" ~ "unique target display (vs. contrastive display)",
    term == "adjTRUE:conditionsize" ~ "adjective * size",
    term == "adjTRUE:searchtypeuniquetarget" ~ "adjective * unique target",
    term == "conditionsize:searchtypeuniquetarget" ~ "size * unique target",
    term == "adjTRUE:conditionsize:searchtypeuniquetarget" ~ "adjective * size * unique target"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Full model of target choice from Experiment 1.")
```

In addition to the analyses reported in the main text, we ran a pre-registered linear mixed effects model predicting target choice from the presence of an adjective in the utterance, the adjective type (size or color), and the display type (unique target display or contrastive display) (Table \ref{tab:e1-table}). People were more likely to choose the target if there was an adjective in the utterance ($\beta_{adjective} =$ `r e1full_adj_estimate`, $t =$ `r e1full_adj_statistic`, $p =$ `r e1full_adj_p.value`), and were more overall likely to choose the target on unique target trials ($\beta_{unique} =$ `r e1full_uniquetarget_estimate`, $t =$ `r e1full_uniquetarget_statistic`, $p =$ `r e1full_uniquetarget_p.value`). There was an interaction between the presence of an adjective and the type of adjective, such that people were especially likely to choose the target when there was a size adjective in the utterance ($\beta_{adjective*size} =$ `r e1full_adj_size_estimate`, $t =$ `r e1full_adj_size_statistic`, $p =$ `r e1full_adj_size_p.value`). There was a three-way interaction between the presence of an adjective, the type of adjective, and the search type such that the contrastive strength of size over color was stronger in the contrastive trials than the unique target trials ($\beta_{adjective*size*unique} =$ `r e1full_adj_size_uniquetarget_estimate`, $t =$ `r e1full_adj_size_uniquetarget_statistic`, $p =$ `r e1full_adj_size_uniquetarget_p.value`).


```{r e1-plot, fig.width = 5, fig.height = 4.5, fig.cap = "\\label{fig:e1-plot}Referent choice in both the contrastive display trials and the unique target display trials. "}

condition_names <- c(
                    "contrast" = "contrastive display",
                    "uniquetarget" = "unique target display",
                    "size" = "size",
                    "color" = "color"
                    )

e1_mean_data %>%
  mutate(empirical_stat = if_else(searchtype == "uniquetarget" & 
                                    item == "lure", as.double(NA), empirical_stat),
         item = factor(item, levels = c("target", "lure"))) %>%
  ggplot(aes(x = adjective_used, color = item, label = item, y = empirical_stat)) +
  facet_grid(condition ~ searchtype, labeller = as_labeller(condition_names)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
                  position = position_dodge(.25)) + 
  scale_color_ptol() + 
  ylab("Item chosen") + 
  xlab("") + 
  geom_dl(method = list(dl.trans(x = x - .5), "first.qp", cex=.7)) +
  theme(legend.position = "none")
```

Figure \ref{fig:e1-plot} shows referent choice in both the unique target display trials and the contrastive display trials. Unique target displays had one unique referent (the target) and two identical distractors that differed from it both in shape and the critical feature. Contrastive displays had a target, a contrastive pair which matched the target in shape but had a different critical feature, and a lure which matched the target on the critical shape but differed from it on the critical feature.



```{r webppl-continuous, eval = FALSE}
cont_semantics_utterances <- tibble(utterance = c("dax", "blue dax"),
                                sem_values = c("0.8,0.99", "0.99,0.8")) %>%
  tidyr::expand(utterance, sem_values) %>%
  mutate(all_vals = paste(utterance, sem_values, sep = ","),
         label = if_else(sem_values == "0.8,0.99", "low_size_high_color", "high_size_low_color"),
         ids = as.character(1:4))


cont_semantics_inference <- map_dfr(cont_semantics_utterances %>% pull(all_vals), 
                               ~webppl(program_file = 
                                         here("webppl/continuous_semantics.wppl"), 
                                       data = .x),
                               .id = "ids") %>%
  left_join(cont_semantics_utterances, by = "ids") %>%
  as_tibble()  %>%
  select(-all_vals)



write_csv(cont_semantics_inference, here("webppl/model_estimates/continuous_semantics.csv"))
```

```{r load-webppl-continuous}
cont_semantics_inference <- read_csv(here("webppl/model_estimates/continuous_semantics.csv"),
                                 show_col_types = FALSE)
```

\subsection{Modeling Experiment 1 with continuous semantics}

@degen_when_2020 capture asymmetries in description of size and color by positing that different features have different semantic strength. They posit that color has stronger semantics than size, such that "red table" is a better literal description of a small red table than "small table" is. Under these assumptions, RSA using these continuous semantics explains people's tendency to mention color more often than size in a variety of tasks. Can their model explain the asymmetry we find between color and size in Experiment 1? 

In Experiment 1, we found that people more consistently choose the target using contrastive inferences about size than color. We incorporated their continuous semantics into our RSA model of referent choice, which reasons over possible lexicons. In Figure \ref{fig:continuous-sem-plot} we show the difference in referent choice when a feature has low semantic strength (0.8) compared to high semantic strength (0.99). A feature with low semantic strength results in a weaker contrastive inference (reduced choice of the target in the *adjective noun* trials) compared to a feature with high semantic strength. @degen_when_2020 find that color has stronger semantics than size, which would result in a stronger contrastive inference about referent choice when color adjectives are used. This is not what we find: people make stronger contrastive inferences about referent choice when *size* adjectives are used. Thus, while a model with continuous semantics could in principle explain the asymmetry we find, it would need to have stronger semantic values for size than color. We note that while the same continuous semantics do not explain both our data and the production data from @degen_when_2020, neither does the model we propose explain the production data. We leave it to future work to form a more complete account of color-size asymmetries in both production and comprehension.

```{r continuous-sem-plot, fig.width = 5, fig.height = 4.5, fig.cap = "\\label{fig:continuous-sem-plot}Results of modeling target choice in Experiment 1 using continuous semantics. Stronger continuous semantics predict higher choice of the target, while weaker continuous semantics predict lower choice of the target. "}

cont_semantics_inference %>%
  mutate(utterance_cond = if_else(utterance == "dax", "noun", "adjective noun"),
         utterance_cond = factor(utterance_cond, levels = c("noun", "adjective noun")),
         semantic_val = if_else(label == "high_size_low_color", 
                                "Low semantic strength", "High semantic strength"),
         semantic_val = factor(semantic_val, levels = c("Low semantic strength", "High semantic strength")),
         choice = case_when(obj == "blue dax" & world_string == "two dax" ~ "target",
                            obj == "blue dax" & world_string == "two toma" ~ "lure",
                            obj != "blue dax" ~ "other")) %>%
  group_by(utterance_cond, semantic_val, choice) %>%
  summarise(prob = sum(prob)) %>%
  filter(choice != "other") %>%
  ggplot(aes(x = utterance_cond, color = choice, fill = choice)) + 
  geom_crossbar(aes(ymin = prob, ymax = prob, y = prob),
                position = position_dodge(.5), width = .5,
           alpha = .5, size = .5) + 
  facet_wrap(~ semantic_val) +
  labs(x = "Utterance", y = "Proportion each item is chosen") +
  scale_color_ptol() +
  scale_fill_ptol() +
  geom_dl(aes(label = choice, y = prob), 
          position = position_dodge(.5),
          method = list(dl.trans(y = y - 0.5), "last.points", cex=.7)) +
  theme(legend.position = "none")

# Our webppl code is set up to do both color and size with different semantic values, but we're only doing
# inference over "color" values here as a demonstration, so we can relabel to just "low semantic strength" and 
# "high semantic strength".
```

\section{Experiment 2}

```{r e2-read-data}
e2_color_data <- read_csv(here("data/exp2/color.csv"), 
                          show_col_types = FALSE) %>%
  mutate(condition = "color", targetsize = "big") %>%
  rename(adj = colorasked, distractorfeature = distractorcolor)

e2_size_data <- read_csv(here("data/exp2/size.csv"),
                         show_col_types = FALSE) %>%
  mutate(condition = "size") %>%
  rename(adj = sizeasked, distractorfeature = distractorsize)

e2_data <- rbind(e2_color_data, e2_size_data) %>%
  mutate(subid = paste0(subid, condition))

e2_keep_subjs <- e2_data %>%
  filter(searchtype == "attncheck", attncheckscore >= 6) %>%
  group_by(subid) 

e2_model_data <- e2_data %>%
  filter(subid %in% e2_keep_subjs$subid) %>%
  mutate(rtsearch = rtsearch - 6500) %>%
  mutate(log_rt = log(rtsearch)) %>%
  filter(trialtype != 0)

e2_subj_data <- e2_data %>%
  filter(subid %in% e2_keep_subjs$subid) %>%
  filter(trialtype != 0) %>%
  rename(adjective = adj) %>%
  mutate(searchtype = if_else(searchtype == "polychrome" | 
                                searchtype == "differentsizes",
                                      "different", searchtype)) %>%
  mutate(searchtype = if_else(searchtype == "monochrome" |
                                searchtype == "samesize",
                                      "same", searchtype)) %>%
  mutate(rtsearch = rtsearch - 6500) %>%
  mutate(log_rt = log(rtsearch)) %>%
  mutate(adjective = if_else(adjective == TRUE, "adjective noun", "noun"),
         adjective = factor(adjective, levels = c("noun", "adjective noun")),
         searchtype = factor(searchtype, levels = c("different", "contrast", "same")))

e2_mean_data <- e2_subj_data %>%
  group_by(searchtype, adjective, condition) %>%
  tidyboot_mean(percentage)

e2_model <- lmer(percentage ~ condition * adjective * searchtype +
                (adjective | subid),
              control = lmerControl(optimizer = "bobyqa"),
              data = e2_subj_data) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(p.value = printp(p.value))

walk2(c("e2_adj", "e2_search_same", "e2_search_contrast", "e2_adj_contrast", "e2_adj_same"), 
      c("adjectiveadjective noun", "searchtypesame", "searchtypecontrast",
        "adjectiveadjective noun:searchtypecontrast", "adjectiveadjective noun:searchtypesame"), 
      ~ make_text_vars(e2_model, .x, .y))
```

\subsection{Experiment 2 Prevalence Judgments}
The full regression of prevalence judgments, also reported in the main text, is in Table \ref{tab:e2-table}.

```{r e2-table}
e2_model %>%
  select(term, estimate, statistic, p.value) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "adjectiveadjective noun" ~ "adjective (vs. no adjective)",
    term == "conditionsize" ~ "size (vs. color)",
    term == "searchtypecontrast" ~ "within-category contrast display (vs. between-category contrast)",
    term == "searchtypesame" ~ "same feature display (vs. between-category contrast)",
    term == "conditionsize:adjectiveadjective noun" ~ "size * adjective",
    term == "conditionsize:searchtypecontrast" ~ "size * within-category contrast display",
    term == "conditionsize:searchtypesame" ~ "size * same feature display",
    term == "adjectiveadjective noun:searchtypecontrast" ~ "adjective * within-category contrast display",
    term == "adjectiveadjective noun:searchtypesame" ~ "adjective * same feature display",
    term == "conditionsize:adjectiveadjective noun:searchtypecontrast" ~ "size * adjective * within-category contrast display",
    term == "conditionsize:adjectiveadjective noun:searchtypesame" ~ "size * adjective * same feature display"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Full model of prevalence judgments from Experiment 2.")


```

\section{Experiment 3}

```{r e3-read-data}
e3_data <- read_csv(here("data/exp3_turk_data.csv"), show_col_types = FALSE)

# participants who have unbalanced numbers of trials in each condition
e3_exclude <- e3_data %>% count(subid, utttype, searchtype) %>% filter(n == 2 | n == 3)

e3_keep_subjs <- e3_data %>%
  filter(searchtype == "colorcheck", chosetarget == TRUE, attncheckscore >= 6) %>%
  filter(!(subid %in% e3_exclude$subid)) %>%
  group_by(subid) %>%
  count() %>%
  filter(n == 4)

e3_model_data <- e3_data %>%
  filter(subid %in% e3_keep_subjs$subid) %>%
  filter(trialtype != 0) %>%
  mutate(searchtype = factor(searchtype, levels = c("differentshapes", "contrast")))

e3_subj_data <- e3_data %>%
  filter(subid %in% e3_keep_subjs$subid) %>%
  filter(trialtype != 0) %>%
  mutate(searchtype = if_else(searchtype == "differentshapes",
                                      "different", searchtype)) %>%
  mutate(rtsearch = rtsearch - 6500) %>% # time before selections can be made
  mutate(log_rt = log(rtsearch)) %>%
  mutate(adjective = if_else(utttype == "adj", "adjective noun", utttype),
         adjective = if_else(adjective == "noutt", "alien utterance", 
                             adjective),
         adjective = if_else(adjective == "noadj", "noun", adjective),
         adjective = factor(adjective, 
                            levels = c("noun", "adjective noun", 
                                       "alien utterance")),
         searchtype = factor(searchtype, levels = c("different", "contrast")))

e3_mean_data <- e3_subj_data %>%
  group_by(searchtype, adjective, condition) %>%
  tidyboot_mean(percentage)

e3_model <- lmer(percentage ~ condition * adjective * searchtype +
                (adjective | subid),
              control = lmerControl(optimizer = "bobyqa"),
              data = e3_subj_data) %>%
  tidy() %>%
  filter(effect == "fixed")
```

```{r e3-models}
# all prereg'd models below

e3_utt_model_no_alien <- e3_model_data %>%
  filter(utttype != "noutt") %>%
  mutate(utttype = factor(utttype, levels = c("noadj", "adj"))) %>%
  lmer(percentage ~ utttype + (utttype|subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(p.value = printp(p.value))

make_text_vars(e3_utt_model_no_alien, "e3_adj_no_alien", "utttypeadj")

e3_utt_model <- e3_model_data %>%
  mutate(utttype = factor(utttype, levels = c("noutt", "noadj", "adj"))) %>%
  lmer(percentage ~ utttype + (utttype | subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(p.value = printp(p.value))

walk2(c("e3_utt_model_adj", "e3_utt_model_noadj"), 
      c("utttypeadj", "utttypenoadj"), 
      ~ make_text_vars(e3_utt_model, .x, .y))

# model did not converge with maximal slopes
e3_full_model <- e3_model_data %>%
  mutate(utttype = factor(utttype, levels = c("noutt", "noadj", "adj"))) %>%
  lmer(percentage ~ utttype * searchtype * condition + 
         (utttype | subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = papaja::printp(p.value))

walk2(c("e3_full_noadj", "e3_full_adj", "e3_full_size", "e3_full_contrast", "e3_full_adj_size"), 
      c("utttypenoadj", "utttypeadj", "conditionsize", "searchtypecontrast", "utttypeadj:conditionsize"), 
      ~ make_text_vars(e3_full_model, .x, .y))

e3_full_model_no_alien <- e3_model_data %>%
  filter(utttype != "noutt") %>%
  mutate(utttype = factor(utttype, levels = c("noadj", "adj"))) %>%
  lmer(percentage ~ utttype * searchtype * condition + 
         (utttype | subid), data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = papaja::printp(p.value))

make_text_vars(e3_full_model_no_alien, "e3_noalien_adj", "utttypeadj")

```

The full regression predicting Experiment 3 prevalence judgments, also reported in the main text, is shown in Table \ref{tab:e3-full}. The regression predicting Experiment 3 prevalence judgments among only adjective utterances and no adjective utterances (excluding alien utterance trials), also reported in the main text, is shown in Table \ref{tab:e3-full-no-alien}.

In addition to the regressions reported in the manuscript, we two pre-registered, targeted regressions to test the effect of utterance type to more specifically in case these effects were unclear in the maximal models. First, we filtered to adjective and no adjective trials and fit a linear mixed effects model predicting prevalence judgment by utterance type with a random slope of utterance type by subject (Table \ref{tab:e3-adj-no-alien}). Participants' prevalence judgments were significantly lower when an adjective was used in the utterance ($\beta =$ `r e3_adj_no_alien_estimate`, $t =$ `r e3_adj_no_alien_statistic`, $p =$ `r e3_adj_no_alien_p.value`). Second, we included all trials in a linear mixed effects model predicting prevalence judgment by utterance type with a random slope of utterance type by subject (Table \ref{tab:e3-adj}). Utterances without an adjective resulted in significantly higher prevalence judgments than alien utterances ($\beta =$ `r e3_utt_model_noadj_estimate`, $t =$ `r e3_utt_model_noadj_statistic`, $p =$ `r e3_utt_model_noadj_p.value`), and utterances with an adjective did not result in significantly different prevalence judgments than alien utterances ($\beta =$ `r e3_utt_model_adj_estimate`, $t =$ `r e3_utt_model_adj_statistic`, $p =$ `r e3_utt_model_adj_p.value`).

```{r e3-full}
e3_full_model %>%
  select(-std.error, -df) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "utttypeadj" ~ "adjective utterance (vs. alien utterance)",
    term == "utttypenoadj" ~ "no adjective utterance (vs. alien utterance)",
    term == "searchtypecontrast" ~ "within-category contrast display (vs. between-category)",
    term == "conditionsize" ~ "size (vs. color)",
    term == "utttypenoadj:searchtypecontrast" ~ "no adjective utterance * within-category contrast display",
    term == "utttypeadj:searchtypecontrast" ~ "adjective utterance * within-category contrast display",
    term == "utttypenoadj:conditionsize" ~ "no adjective utterance * size",
    term == "utttypeadj:conditionsize" ~ "adjective utterance * size",
    term == "searchtypecontrast:conditionsize" ~ "within-category contrast display",
    term == "utttypenoadj:searchtypecontrast:conditionsize" ~ "no adjective utterance * within-category contrast display * size"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Regression predicting prevalence judgments from utterance type, context type, and adjective type in Experiment 3.")

```

```{r e3-full-no-alien}
e3_full_model_no_alien %>%
  select(-std.error, -df) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "utttypeadj" ~ "adjective utterance (vs. no adjective)",
    term == "searchtypecontrast" ~ "within-category contrast display (vs. between-category)",
    term == "conditionsize" ~ "size (vs. color)",
    term == "utttypeadj:searchtypecontrast" ~ "adjective utterance * within-category contrast display",
    term == "utttypeadj:conditionsize" ~ "adjective utterance * size",
    term == "searchtypecontrast:conditionsize" ~ "within-category contrast display",
    term == "utttypeadj:searchtypecontrast:conditionsize" ~ "no adjective utterance * within-category contrast display * size"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Regression predicting prevalence judgments from utterance type, context type, and adjective type only among adjective and no adjective utterances (excluding alien utterances) in Experiment 3.")

```

```{r e3-adj-no-alien}
e3_utt_model_no_alien %>%
  select(-effect, -group) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "utttypeadj" ~ "adjective utterance (vs. no adjective utterance)"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Regression predicting prevalence judgments from presence of an adjective in the utterance (excluding alien language utterances) in Experiment 3.")

```

```{r e3-adj}
e3_utt_model %>%
  select(-effect, -group) %>%
  rename("p-value" = "p.value") %>%
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "utttypeadj" ~ "adjective utterance (vs. alien utterance)",
    term == "utttypenoadj" ~ "no adjective utterance (vs. alien utterance)"
  )) %>%
  apa_table(format.args = list(na_string = ""), font_size = "footnotesize",
            caption = "Regression predicting prevalence judgments from utterance type in Experiment 3.")

```

\section*{References}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
\noindent
<div id = "refs"></div>
\endgroup